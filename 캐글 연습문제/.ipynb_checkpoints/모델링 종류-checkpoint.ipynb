{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e16db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d575b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['calibration', 'cluster', 'covariance', 'cross_decomposition', 'datasets', 'decomposition', 'dummy', 'ensemble', 'exceptions', 'experimental', 'externals', 'feature_extraction', 'feature_selection', 'gaussian_process', 'inspection', 'isotonic', 'kernel_approximation', 'kernel_ridge', 'linear_model', 'manifold', 'metrics', 'mixture', 'model_selection', 'multiclass', 'multioutput', 'naive_bayes', 'neighbors', 'neural_network', 'pipeline', 'preprocessing', 'random_projection', 'semi_supervised', 'svm', 'tree', 'discriminant_analysis', 'impute', 'compose', 'clone', 'get_config', 'set_config', 'config_context', 'show_versions']\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0688afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5256ef02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AffinityPropagation', 'AgglomerativeClustering', 'Birch', 'DBSCAN', 'OPTICS', 'cluster_optics_dbscan', 'cluster_optics_xi', 'compute_optics_graph', 'KMeans', 'FeatureAgglomeration', 'MeanShift', 'MiniBatchKMeans', 'SpectralClustering', 'affinity_propagation', 'dbscan', 'estimate_bandwidth', 'get_bin_seeds', 'k_means', 'kmeans_plusplus', 'linkage_tree', 'mean_shift', 'spectral_clustering', 'ward_tree', 'SpectralBiclustering', 'SpectralCoclustering']\n"
     ]
    }
   ],
   "source": [
    "print(cluster.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc897ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import k_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55cf7524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function k_means in module sklearn.cluster._kmeans:\n",
      "\n",
      "k_means(X, n_clusters, *, sample_weight=None, init='k-means++', precompute_distances='deprecated', n_init=10, max_iter=300, verbose=False, tol=0.0001, random_state=None, copy_x=True, n_jobs='deprecated', algorithm='auto', return_n_iter=False)\n",
      "    K-means clustering algorithm.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <k_means>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "        The observations to cluster. It must be noted that the data\n",
      "        will be converted to C ordering, which will cause a memory copy\n",
      "        if the given data is not C-contiguous.\n",
      "    \n",
      "    n_clusters : int\n",
      "        The number of clusters to form as well as the number of\n",
      "        centroids to generate.\n",
      "    \n",
      "    sample_weight : array-like of shape (n_samples,), default=None\n",
      "        The weights for each observation in X. If None, all observations\n",
      "        are assigned equal weight.\n",
      "    \n",
      "    init : {'k-means++', 'random'}, callable or array-like of shape             (n_clusters, n_features), default='k-means++'\n",
      "        Method for initialization:\n",
      "    \n",
      "        'k-means++' : selects initial cluster centers for k-mean\n",
      "        clustering in a smart way to speed up convergence. See section\n",
      "        Notes in k_init for more details.\n",
      "    \n",
      "        'random': choose `n_clusters` observations (rows) at random from data\n",
      "        for the initial centroids.\n",
      "    \n",
      "        If an array is passed, it should be of shape (n_clusters, n_features)\n",
      "        and gives the initial centers.\n",
      "    \n",
      "        If a callable is passed, it should take arguments X, n_clusters and a\n",
      "        random state and return an initialization.\n",
      "    \n",
      "    precompute_distances : {'auto', True, False}\n",
      "        Precompute distances (faster but takes more memory).\n",
      "    \n",
      "        'auto' : do not precompute distances if n_samples * n_clusters > 12\n",
      "        million. This corresponds to about 100MB overhead per job using\n",
      "        double precision.\n",
      "    \n",
      "        True : always precompute distances\n",
      "    \n",
      "        False : never precompute distances\n",
      "    \n",
      "        .. deprecated:: 0.23\n",
      "            'precompute_distances' was deprecated in version 0.23 and will be\n",
      "            removed in 1.0 (renaming of 0.25). It has no effect.\n",
      "    \n",
      "    n_init : int, default=10\n",
      "        Number of time the k-means algorithm will be run with different\n",
      "        centroid seeds. The final results will be the best output of\n",
      "        n_init consecutive runs in terms of inertia.\n",
      "    \n",
      "    max_iter : int, default=300\n",
      "        Maximum number of iterations of the k-means algorithm to run.\n",
      "    \n",
      "    verbose : bool, default=False\n",
      "        Verbosity mode.\n",
      "    \n",
      "    tol : float, default=1e-4\n",
      "        Relative tolerance with regards to Frobenius norm of the difference\n",
      "        in the cluster centers of two consecutive iterations to declare\n",
      "        convergence.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Determines random number generation for centroid initialization. Use\n",
      "        an int to make the randomness deterministic.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    copy_x : bool, default=True\n",
      "        When pre-computing distances it is more numerically accurate to center\n",
      "        the data first. If copy_x is True (default), then the original data is\n",
      "        not modified. If False, the original data is modified, and put back\n",
      "        before the function returns, but small numerical differences may be\n",
      "        introduced by subtracting and then adding the data mean. Note that if\n",
      "        the original data is not C-contiguous, a copy will be made even if\n",
      "        copy_x is False. If the original data is sparse, but not in CSR format,\n",
      "        a copy will be made even if copy_x is False.\n",
      "    \n",
      "    n_jobs : int, default=None\n",
      "        The number of OpenMP threads to use for the computation. Parallelism is\n",
      "        sample-wise on the main cython loop which assigns each sample to its\n",
      "        closest center.\n",
      "    \n",
      "        ``None`` or ``-1`` means using all processors.\n",
      "    \n",
      "        .. deprecated:: 0.23\n",
      "            ``n_jobs`` was deprecated in version 0.23 and will be removed in\n",
      "            1.0 (renaming of 0.25).\n",
      "    \n",
      "    algorithm : {\"auto\", \"full\", \"elkan\"}, default=\"auto\"\n",
      "        K-means algorithm to use. The classical EM-style algorithm is \"full\".\n",
      "        The \"elkan\" variation is more efficient on data with well-defined\n",
      "        clusters, by using the triangle inequality. However it's more memory\n",
      "        intensive due to the allocation of an extra array of shape\n",
      "        (n_samples, n_clusters).\n",
      "    \n",
      "        For now \"auto\" (kept for backward compatibiliy) chooses \"elkan\" but it\n",
      "        might change in the future for a better heuristic.\n",
      "    \n",
      "    return_n_iter : bool, default=False\n",
      "        Whether or not to return the number of iterations.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    centroid : ndarray of shape (n_clusters, n_features)\n",
      "        Centroids found at the last iteration of k-means.\n",
      "    \n",
      "    label : ndarray of shape (n_samples,)\n",
      "        label[i] is the code or index of the centroid the\n",
      "        i'th observation is closest to.\n",
      "    \n",
      "    inertia : float\n",
      "        The final value of the inertia criterion (sum of squared distances to\n",
      "        the closest centroid for all observations in the training set).\n",
      "    \n",
      "    best_n_iter : int\n",
      "        Number of iterations corresponding to the best results.\n",
      "        Returned only if `return_n_iter` is set to True.\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(help(k_means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bb43b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BaseEnsemble', 'RandomForestClassifier', 'RandomForestRegressor', 'RandomTreesEmbedding', 'ExtraTreesClassifier', 'ExtraTreesRegressor', 'BaggingClassifier', 'BaggingRegressor', 'IsolationForest', 'GradientBoostingClassifier', 'GradientBoostingRegressor', 'AdaBoostClassifier', 'AdaBoostRegressor', 'VotingClassifier', 'VotingRegressor', 'StackingClassifier', 'StackingRegressor']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "print(ensemble.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74937244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ARDRegression', 'BayesianRidge', 'ElasticNet', 'ElasticNetCV', 'Hinge', 'Huber', 'HuberRegressor', 'Lars', 'LarsCV', 'Lasso', 'LassoCV', 'LassoLars', 'LassoLarsCV', 'LassoLarsIC', 'LinearRegression', 'Log', 'LogisticRegression', 'LogisticRegressionCV', 'ModifiedHuber', 'MultiTaskElasticNet', 'MultiTaskElasticNetCV', 'MultiTaskLasso', 'MultiTaskLassoCV', 'OrthogonalMatchingPursuit', 'OrthogonalMatchingPursuitCV', 'PassiveAggressiveClassifier', 'PassiveAggressiveRegressor', 'Perceptron', 'Ridge', 'RidgeCV', 'RidgeClassifier', 'RidgeClassifierCV', 'SGDClassifier', 'SGDRegressor', 'SquaredLoss', 'TheilSenRegressor', 'enet_path', 'lars_path', 'lars_path_gram', 'lasso_path', 'orthogonal_mp', 'orthogonal_mp_gram', 'ridge_regression', 'RANSACRegressor', 'PoissonRegressor', 'GammaRegressor', 'TweedieRegressor']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "print(linear_model.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe859ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LinearSVC', 'LinearSVR', 'NuSVC', 'NuSVR', 'OneClassSVM', 'SVC', 'SVR', 'l1_min_c']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "print(svm.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edbbcc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.1-py3-none-win_amd64.whl (125.4 MB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda3\\lib\\site-packages (from xgboost) (1.6.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c0d7b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DMatrix', 'DeviceQuantileDMatrix', 'Booster', 'DataIter', 'train', 'cv', 'RabitTracker', 'build_info', 'plot_importance', 'plot_tree', 'to_graphviz', 'set_config', 'get_config', 'config_context', 'XGBModel', 'XGBClassifier', 'XGBRegressor', 'XGBRanker', 'XGBRFClassifier', 'XGBRFRegressor', 'dask']\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "print(xgboost.__all__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43409b41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
